{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eabbb5d5-22b9-4f0b-aeaf-d61710853901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Autoloader\n",
    "## Introduction to Autoloader\n",
    "\n",
    "Autoloader is a Databricks feature designed for efficient, scalable, and incremental ingestion of new data files as they arrive in cloud storage (e.g., ADLS, S3, GCS). It enables processing of massive datasets in a cost-effective way without manual file tracking.\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- Incrementally and automatically detects new files\n",
    "- Scalable for large numbers of files\n",
    "- Supports schema evolution\n",
    "- Can ingest from multiple cloud providers\n",
    "\n",
    "## How Autoloader Works\n",
    "\n",
    "- **Directory Listing Mode:** Default and most efficient for cloud object stores. Lists files and processes only new ones.\n",
    "- **File Notification Mode:** Integrates with cloud-native notifications for higher performance and reliability.\n",
    "- **Checkpointing:** Tracks which files have already been processed (using a checkpoint location) to prevent duplicate ingestion.\n",
    "\n",
    "## Common Use Cases\n",
    "\n",
    "- Streaming ingestion of files into a Delta Lake table\n",
    "- Near real-time ETL pipelines\n",
    "- Data lake ingestion patterns\n",
    "\n",
    "## Example Scenario Using Sample Files\n",
    "\n",
    "We'll demonstrate how to use Autoloader to ingest the following files:\n",
    "\n",
    "- `customer_details.csv`\n",
    "- `product_catalog.csv`\n",
    "- `sales.csv`\n",
    "\n",
    "Assume these files arrive incrementally in a folder such as `/FileStore/data/input/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ae1f97e-a6e6-4f02-a188-9673cd5cabcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step-by-Step Example: Using Autoloader\n",
    "\n",
    "### 1. Basic Autoloader Setup (CSV Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57fec87c-ee3e-4d91-9def-6ba2ea30139f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "input_path = \"/FileStore/data/\"\n",
    "checkpoint_path = \"/FileStore/data/checkpoints/autoloader_demo/\"\n",
    "output_path = \"/FileStore/data/out\"\n",
    "schema_location = \"/FileStore/data/schema/autoloader_demo/\"\n",
    "\n",
    "sales_schema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType()),\n",
    "    StructField(\"SalesOrderLineNumber\", StringType()),\n",
    "    StructField(\"OrderDate\", StringType()),\n",
    "    StructField(\"CustomerID\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"Quantity\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", DoubleType()),\n",
    "    StructField(\"TaxAmount\", DoubleType()),\n",
    "])\n",
    "\n",
    "sales_df = (\n",
    "  spark.readStream\n",
    "      .format(\"cloudFiles\")\n",
    "      .option(\"cloudFiles.format\", \"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .option(\"cloudFiles.schemaLocation\", schema_location)\n",
    "      .schema(sales_schema)\n",
    "      .load(input_path)\n",
    ")\n",
    "\n",
    "query = (\n",
    "  sales_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path)\n",
    "    .trigger(availableNow=True)\n",
    "    .start(output_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b89bf717-2375-483a-acc9-e4fd074de222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Autoloader with Schema Evolution\n",
    "If you expect the schema to change (columns added/removed), enable schema evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0c64e7c-0f13-4645-a24b-414b86fc94ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_df = (\n",
    "    spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .option(\"cloudFiles.schemaLocation\", checkpoint_path + \"/schema/\")\n",
    "            .load(input_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fa2aa9f-a555-4001-b71c-f755f2f54e42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Autoloader with Multiple File Types\n",
    "\n",
    "If your input folder has mixed file types (e.g., CSV and JSON):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b304f020-f294-4fea-a2ab-a194e62c9551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_df = (\n",
    "    spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\") # or \"json\"\n",
    "            .option(\"header\", True)\n",
    "            .load(input_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0421a28d-522f-4132-b153-f2e3ab821e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Hands-On Exercise\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "1. Place all sample files in `/FileStore/data/input/`.\n",
    "2. Run the above notebook cells to create a Delta table from the ingested data.\n",
    "3. Monitor the stream, add a new file, and confirm that Autoloader picks it up automatically.\n",
    "4. Query the Delta table in a new cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b611aedd-a801-4296-bc39-4bee0d8bb9a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------+----------+--------------------+--------+---------+---------+\n|SalesOrderNumber|SalesOrderLineNumber| OrderDate|CustomerID|                Item|Quantity|UnitPrice|TaxAmount|\n+----------------+--------------------+----------+----------+--------------------+--------+---------+---------+\n|         SO20000|                   2|2024-08-24|  CUST2373|      Running Shorts|       4|   278.63|    55.73|\n|         SO20001|                   2|2024-10-06|  CUST2779|      Vacuum Cleaner|       4|   111.58|    22.32|\n|         SO20002|                   2|2024-08-02|  CUST2732|       Tennis Racket|       6|   152.03|    45.61|\n|         SO20003|                   3|2024-09-21|  CUST1815|     Children's Book|       3|     6.62|     0.99|\n|         SO20004|                   2|2025-03-18|  CUST2913|                Doll|       7|    31.13|     10.9|\n|         SO20005|                   3|2024-12-30|  CUST1241| Vitamin Supplements|       2|   247.52|    24.75|\n|         SO20006|                   2|2024-09-17|  CUST2392|      Pruning Shears|       9|    307.9|   138.56|\n|         SO20007|                   1|2024-08-05|  CUST2277|          Remote Car|       7|      6.8|     2.38|\n|         SO20008|                   3|2024-07-04|  CUST1977|        Coffee Maker|       2|   493.13|    49.31|\n|         SO20009|                   4|2025-03-30|  CUST1598|          Car Vacuum|       4|    98.41|    19.68|\n|         SO20010|                   1|2024-10-08|  CUST1783|       First Aid Kit|       3|   102.73|    15.41|\n|         SO20011|                   3|2024-09-29|  CUST2199|       Running Shoes|       9|    37.97|    17.09|\n|         SO20012|                   1|2025-03-05|  CUST1976|      Hand Sanitizer|       5|    67.13|    16.78|\n|         SO20013|                   3|2024-11-05|  CUST2508|Blood Pressure Mo...|       4|   172.01|     34.4|\n|         SO20014|                   2|2024-08-12|  CUST2431|              Jacket|       7|   178.65|    62.53|\n|         SO20015|                   2|2025-03-05|  CUST1169|Blood Pressure Mo...|       5|   172.01|     43.0|\n|         SO20016|                   2|2024-11-18|  CUST1637|         Nail Polish|       6|   101.32|     30.4|\n|         SO20017|                   2|2024-06-16|  CUST1983|Blood Pressure Mo...|       1|   172.01|      8.6|\n|         SO20018|                   4|2024-11-06|  CUST1558|                Doll|       1|    31.13|     1.56|\n|         SO20019|                   3|2025-05-25|  CUST1370|            Cookbook|       9|    42.12|    18.95|\n+----------------+--------------------+----------+----------+--------------------+--------+---------+---------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(output_path).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "720d925e-0a71-4bec-a1da-91f810d8dd1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Additional Tips\n",
    "\n",
    "- **File Naming:** Use unique file names for each batch to avoid duplicates.\n",
    "- **Checkpoints:** Use a unique checkpoint directory for each streaming query.\n",
    "- **Performance:** For production, consider tuning options like `cloudFiles.maxFilesPerTrigger`."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Autoloader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}